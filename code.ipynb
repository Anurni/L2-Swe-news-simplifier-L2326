{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from transformers import Trainer, MT5Model, AutoTokenizer, pipeline, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, MT5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "all_data = []\n",
    "\n",
    "with open('data.json', 'r') as data:\n",
    "    data = json.load(data)\n",
    "    for datapoint in data:\n",
    "        entry = {\n",
    "            \"original_headline\": datapoint['original']['headline'],\n",
    "            \"original_article\": datapoint['original']['article'],\n",
    "            \"target_headline\": datapoint['simplified']['headline'],\n",
    "            \"target_article\": datapoint['simplified']['article']\n",
    "        }\n",
    "        all_data.append(entry)\n",
    "\n",
    "# splitting the data\n",
    "\n",
    "training_data, test_data = train_test_split(all_data, test_size=0.2)        \n",
    "\n",
    "# creating datasets \n",
    "\n",
    "train_dataset = Dataset.from_list(training_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annin\\anaconda3\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiating tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function\n",
    "\n",
    "# TO DO! CHECK HOW TO ALSO INCLUDE THE ARTICLE HEADLINE\n",
    "\n",
    "def preprocess_function(data):\n",
    "    inputs = [article for article in data['original_article']]\n",
    "    model_inputs = tokenizer(inputs, max_length=500, truncation=True, padding=True, return_tensors='pt')\n",
    "    labels = tokenizer(text_target=data['target_article'], max_length=200, truncation=True, padding=True, return_tensors='pt')\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843ff04cd5fc4c3fbaa477542c2f1b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e36bcdf0902485cb34c7bea16d8a0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_headline': 'Claudia Sheinbaum blir Mexikos första kvinnliga president', 'original_article': 'Ett val kantat av dödligt våld har nått sitt slut. Claudia Sheinbaum blir Mexikos första kvinnliga president. Det första officiella preliminära resultatet pekade på en överlägsen seger för Claudia Sheinbaum, som tillhör det regerande partiet Morena. Enligt beräkningar från Mexikos internationella valinstitut har Sheinbaum fått drygt 60 procent av rösterna, samtidigt som huvudmotståndaren Xóchitl Gálvez har fått cirka 25 procent av rösterna. Morena, som redan tidigare utropat seger, kommer att fortsätta med en enkel majoritet i landets kongress, säger partichefen Mario Delgado under en nationell tv-sändning. Största och farligaste valet Mexikos största val någonsin har också varit det mest våldsamma i modern historia, med dödandet av 38 kandidater. Våldet har väckt oro i landet att demokratin ligger under hot av de stridande drogkartellerna. Att konfrontera och minska den organiserade brottsligheten som präglar flera delar av Mexiko kommer bli ett av Sheinbaums viktigaste uppdrag. Den 1 oktober väntas hon inta stolen som president under en period på sex år. Vallokal fick stänga efter skottlossning Det dödliga våldet tog inte paus under söndagens röstande. En vallokal i staden i Coyomeapan i delstaten Puebla fick stänga efter att en person dödats i en skottlossning, rapporterade den statliga valmyndigheten. Delstatens regionala åklagare bekräftade ytterligare ett dödsfall vid en vallokal i Tlapanalá, också i Puebla.', 'target_headline': 'Ny president i Mexiko', 'target_article': 'Mexiko har en ny president. Hon heter Claudia Sheinbaum. Hon är den första kvinnan som blir president i Mexiko. I tisdags började hon sitt nya jobb. Hon höll ett tal i Mexikos riksdag. Hon lovade att priserna på mat och bensin inte ska bli för höga. Hon lovade också fler bostäder och tåg i Mexiko. Mexiko har flera problem. Ett av problemen är gäng med brottslingar som säljer droger. De har mycket makt. Claudia Sheinbaum är 62 år. Hon vann valet i juni. Hon fick 60 procent av rösterna. Sheinbaum är med i partiet Morena som är till vänster i politiken.', 'input_ids': [30169, 4823, 83209, 270, 526, 84035, 3075, 300, 97769, 588, 259, 272, 15681, 8873, 19826, 260, 259, 81352, 4630, 348, 57609, 259, 5167, 259, 142798, 337, 17155, 262, 66812, 4970, 13243, 260, 1136, 17155, 262, 29389, 2599, 786, 64822, 56600, 259, 94920, 603, 42219, 482, 289, 6306, 160504, 1922, 259, 168916, 875, 259, 81352, 4630, 348, 57609, 261, 512, 1098, 49242, 551, 13838, 50360, 259, 71311, 3398, 377, 260, 642, 3075, 390, 142757, 372, 259, 2877, 259, 142798, 337, 83870, 2599, 4823, 88756, 588, 4630, 348, 57609, 1527, 3996, 20804, 2964, 1617, 12972, 526, 259, 225070, 377, 261, 2290, 11385, 270, 512, 54772, 33215, 58411, 4190, 959, 553, 77135, 280, 489, 4642, 4988, 588, 1527, 3996, 59930, 262, 877, 12972, 526, 259, 225070, 377, 260, 3398, 377, 261, 512, 259, 47344, 259, 11385, 825, 259, 98417, 4840, 259, 168916, 261, 3683, 713, 10476, 46945, 499, 289, 19897, 31197, 429, 259, 266, 259, 17232, 263, 68320, 263, 261, 259, 263, 17843, 3990, 218186, 22703, 459, 120018, 1711, 289, 294, 216849, 5701, 264, 263, 226786, 260, 1819, 88385, 597, 259, 102355, 11053, 259, 95919, 259, 142798, 337, 3656, 88385, 4823, 2537, 56446, 348, 588, 259, 7482, 721, 259, 33680, 551, 6405, 300, 97769, 54035, 259, 266, 4472, 8664, 261, 499, 84035, 31449, 526, 3754, 38535, 295, 260, 434, 97769, 429, 588, 300, 40811, 270, 16347, 259, 266, 259, 17232, 713, 55575, 272, 8626, 295, 1711, 6800, 526, 269, 138430, 4740, 17854, 2229, 51690, 377, 260, 18021, 150954, 1194, 597, 1342, 1855, 530, 22394, 16333, 259, 219731, 84503, 512, 115950, 106359, 4681, 262, 269, 845, 526, 259, 142798, 268, 3683, 4113, 2275, 526, 4630, 348, 57609, 263, 259, 11898, 11053, 259, 105403, 260, 2528, 333, 259, 13456, 259, 43263, 358, 6966, 259, 6344, 259, 99042, 512, 13243, 1711, 289, 8192, 482, 1528, 2659, 260, 5130, 152364, 259, 21464, 259, 112638, 262, 3052, 259, 72700, 79941, 1009, 1136, 84035, 4970, 300, 97769, 429, 27882, 1966, 97377, 1711, 158579, 8278, 263, 144904, 4740, 260, 642, 4823, 152364, 259, 266, 259, 57412, 259, 266, 1288, 276, 26589, 15766, 259, 266, 426, 94483, 259, 69898, 262, 259, 21464, 259, 112638, 262, 3052, 713, 289, 2985, 84035, 7045, 259, 266, 289, 259, 72700, 79941, 1009, 261, 8926, 16333, 530, 9853, 4970, 4823, 125584, 260, 5549, 94483, 263, 19789, 262, 259, 721, 105218, 825, 390, 86590, 2663, 54832, 60321, 2275, 84035, 263, 8279, 3963, 289, 4823, 152364, 259, 266, 366, 82999, 473, 471, 261, 259, 7482, 721, 259, 266, 259, 69898, 262, 260, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [259, 142798, 268, 588, 289, 1149, 13243, 260, 15254, 112697, 259, 81352, 4630, 348, 57609, 260, 15254, 961, 530, 17155, 262, 66812, 321, 512, 259, 5167, 13243, 259, 266, 259, 142798, 268, 260, 336, 24712, 59856, 9783, 40231, 6966, 8873, 259, 647, 7188, 260, 15254, 382, 31143, 2275, 2319, 259, 266, 259, 142798, 337, 110497, 5951, 260, 15254, 259, 35281, 368, 713, 10842, 377, 482, 3071, 597, 218616, 272, 1966, 4429, 4113, 875, 15205, 262, 260, 15254, 259, 35281, 368, 259, 7482, 721, 4681, 759, 104611, 597, 259, 133135, 259, 266, 259, 142798, 268, 260, 259, 142798, 268, 588, 4681, 262, 3091, 260, 30169, 526, 259, 72155, 961, 259, 80382, 499, 259, 219731, 176134, 512, 259, 119684, 295, 17854, 295, 260, 459, 588, 326, 8616, 128734, 260, 259, 81352, 4630, 348, 57609, 961, 8950, 2659, 260, 15254, 36730, 259, 95919, 259, 266, 11176, 260, 15254, 259, 21464, 1617, 12972, 526, 259, 225070, 377, 260, 4630, 348, 57609, 961, 499, 259, 266, 259, 71311, 3398, 377, 512, 961, 1098, 161033, 259, 266, 259, 214542, 260, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# apply preprocessing function to the dataset\n",
    "\n",
    "tokenized_training_data = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_data = test_dataset.map(preprocess_function, batched=True)\n",
    "print(tokenized_test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataloader \n",
    "\n",
    "train_dataloader = DataLoader(tokenized_training_data, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(tokenized_test_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model and data collator\n",
    "model =  MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training arguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"L2-swedish-news-article-simplifier-model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=4,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    bf16=True, #change to bf16=True for XPU\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the trainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training_data,\n",
    "    eval_dataset=tokenized_test_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7c8c76f14e4782b14852af1bd2b8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 24.3882, 'grad_norm': 6313.2724609375, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b180e7cc746f2ab2de1a72a633945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 18.147262573242188, 'eval_runtime': 20.3563, 'eval_samples_per_second': 0.491, 'eval_steps_per_second': 0.147, 'epoch': 1.0}\n",
      "{'loss': 24.028, 'grad_norm': 4591.36669921875, 'learning_rate': 1e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a3558bba8f4d4094ca4866db1bd397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 17.991456985473633, 'eval_runtime': 19.0956, 'eval_samples_per_second': 0.524, 'eval_steps_per_second': 0.157, 'epoch': 2.0}\n",
      "{'loss': 23.3125, 'grad_norm': 9938.4072265625, 'learning_rate': 5e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac95c514c864c3286a96abc015dbd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 17.781085968017578, 'eval_runtime': 19.9806, 'eval_samples_per_second': 0.5, 'eval_steps_per_second': 0.15, 'epoch': 3.0}\n",
      "{'loss': 21.742, 'grad_norm': 3273.98291015625, 'learning_rate': 0.0, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc8cd8f07244b9a939f1b68e7741c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 17.36973762512207, 'eval_runtime': 17.7101, 'eval_samples_per_second': 0.565, 'eval_steps_per_second': 0.169, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1050.7211, 'train_samples_per_second': 0.152, 'train_steps_per_second': 0.038, 'train_loss': 23.367663192749024, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=23.367663192749024, metrics={'train_runtime': 1050.7211, 'train_samples_per_second': 0.152, 'train_steps_per_second': 0.038, 'total_flos': 82617139200000.0, 'train_loss': 23.367663192749024, 'epoch': 4.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuning the model:\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annin\\anaconda3\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "c:\\Users\\annin\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<extra_id_0> i Byttorp'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the outcome with pipeline\n",
    "\n",
    "news_simplifier = pipeline(\"text2text-generation\", model='./L2-swedish-news-article-simplifier-model/checkpoint-40')\n",
    "news_simplifier(\"headline: Ung man hittad död nära fotbollsplan i Borås – misstänkt mord article : Mitt under en pojklagsmatch hittades en okontaktbar person intill fotbollsplanen i Byttorp i Borås på lördagen. Polis larmades till platsen och matchen avbröts. Vid lunchtid meddelade polisen att det rör sig om en man i 20-årsåldern som hittats död. Händelsen utreds som misstänkt mord. Larmet kom in till polisen vid 9.30-tiden på lördagen efter att allmänheten larmat om en okontaktbar person liggandes på marken utomhus i Byttorp i Borås kommun. Personen hittades intill en idrottsanläggning, enligt polisen. – De har spelat fotboll där men vi har avbrutit den så att vi kan jobba ostört, sade Jens Andersson, presstalesperson i polisregion Väst, under förmiddagen. Polisen om misstänkta mordet i Byttorp: Okänd dödsorsak Strax efter klockan 12 bekräftade polisen på sin hemsida att personen som hittats är en man i 20-årsåldern, och att han är avliden. Dödsorsaken är för närvarande okänd och det finns i nuläget ingen misstänkt person i ärendet. – När vi kommer dit strax innan tio är mannen avliden. Just nu vet vi inte hur han har dött och vi kan inte utesluta att han utsatts för brott. Han är identifierad och anhöriga är underrättade, säger Jens Andersson och fortsätter: – Vi kommer vara kvar på platsen så länge det behövs. Just nu samlar vi pusselbitar och försöker skapa oss en bild av vad mannen gjort de sista timmarna. Polisen har spärrat av området i Byttorp, där de även jobbar med att höra personer på plats och försöker skapa sig en bild av händelsen. Även ambulans skickades till plats under förmiddagen, skriver polisen på sin hemsida men är i övrigt förtegen om detaljer kring händelsen. Klubbens ordförande: ”Flyttar dagens matcher” Idrottsanläggningen Byttorps IP är stängt tills vidare. – Vi kommer att flytta dagens matcher, vi hade en match i dag, säger Hanseman Samuelsson, ordförande för Byttorps IP. David Kryssman, klubbchef för ett av lagen som spelade på idrottsplatsen, berättar att laget lånat anläggningen då klubbens egna renoveras. Klubbchefen var själv inte på plats under matchen, men har varit i kontakt med berörda spelare, ledare och föräldrar. – De är chockade såklart. Men samtidigt är det svårt att ta in en sådan obehaglig händelse. Det blir väldigt nära och många av killarna är unga och har aldrig sett en skadad människa innan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
